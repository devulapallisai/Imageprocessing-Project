{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6c7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521daf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filters(ksize=5, sigma=5, theta=10, lambd=1, gamma=1, scale_start=0.5, scale_end=1.5, step=0.2):\n",
    "    ''' This function will precompute scaled and rotated versions of Gabor filters\n",
    "\n",
    "    INPUT PARAMETERS :\n",
    "\n",
    "\n",
    "    ksize      = Gabor filter square window size\n",
    "\n",
    "    sigma      = standard deviation for the Gabor filter\n",
    "\n",
    "    theta      = number of angles that are into consideration\n",
    "\n",
    "    lambd      = wavelength of filter (can be attributed to scale change)\n",
    "\n",
    "    gamma      = gamma correction factor\n",
    "\n",
    "    scale_start= varying scale of Gabor filter starting  value\n",
    "\n",
    "    scale_end  = varying scale of Gabor filter end value\n",
    "\n",
    "    step       = step size of the varying scale of the above Gabor filters\n",
    "\n",
    "    RETURNS :\n",
    "\n",
    "    filters    = 2D matrix with generated Gabor filters where each row represents filters different rotation for\n",
    "                 a given scale similar to SIFT(type = 2D array of 2D array)\n",
    "    '''\n",
    "    # Define the Gabor filter bank\n",
    "    filters = []\n",
    "\n",
    "    # each angle given there are theta number of angles into consideration also can think as angular resolution\n",
    "    angle = (2*np.pi)/theta\n",
    "\n",
    "    for scale in np.arange(scale_start, scale_end, step):\n",
    "        # scales changing from start to end with each step of size step\n",
    "        scale_filters = []\n",
    "        for j in range(theta):\n",
    "            gabor_filter = cv2.getGaborKernel(\n",
    "                (ksize, ksize), np.sqrt(scale)*sigma, j*angle, scale*lambd, gamma, 0, ktype=cv2.CV_32F)\n",
    "            scale_filters.append(gabor_filter/np.sum(gabor_filter))\n",
    "\n",
    "        # rotation invariant scaled version of Gabor filter\n",
    "        averaged_value = np.mean(scale_filters, axis=0)\n",
    "        filters.append(averaged_value)\n",
    "\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d911a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blocks(I, block_size=8):\n",
    "    ''' This function will return sub blocks of image I\n",
    "\n",
    "    INPUT PARAMETERS:\n",
    "\n",
    "    I = grayscale image\n",
    "\n",
    "    block_size = Image is divided into square blocks with each size of this variable for further processing\n",
    "                 (type=integer)\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    square overlapping blocks of size(block_size, block_size) from image I (2D array)\n",
    "\n",
    "    '''\n",
    "    blocks = []\n",
    "    for i in range(0, len(I)-block_size+1):\n",
    "        t = []\n",
    "        for j in range(0, len(I[0])-block_size+1):\n",
    "            block = I[i:i+block_size, j:j+block_size]\n",
    "            t.append(block)  # (M-B+1)*(M-B+1) number of blocks\n",
    "        blocks.append(t)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d77434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matrix_generation(blocks, filters):\n",
    "    ''' This function will return feature matrix of whole image\n",
    "\n",
    "    INPUT PARAMETERS:\n",
    "\n",
    "    blocks = generated sub-blocks of image I\n",
    "\n",
    "    filters = set of Gabor filters with rotated and scaled versions\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    Square a row sorted matrix each representing feature vector of sub-block which has mean of all possible\n",
    "    rotations for a given scale\n",
    "\n",
    "    '''\n",
    "    block_features = np.zeros(\n",
    "        len(blocks)*len(blocks[0]), dtype=[('f_vector', np.ndarray, len(filters)),\n",
    "                                           ('x', int), ('y', int)])\n",
    "    p = 0\n",
    "    for i in range(len(blocks)):\n",
    "        for j in range(len(blocks[i])):\n",
    "            filtered = np.array(\n",
    "                [cv2.filter2D(blocks[i][j], cv2.CV_8UC3, filter) for filter in filters])\n",
    "            feature_vector = np.mean(filtered, axis=(1, 2))\n",
    "            # feature_vector has rotation invariant for given scale\n",
    "            # storing feature vector of each block along with its top left corner coordinates\n",
    "            block_features[p][\"f_vector\"] = feature_vector\n",
    "            block_features[p][\"x\"] = i\n",
    "            block_features[p][\"y\"] = j\n",
    "            p = p+1\n",
    "            # at each i,j position of Image I compute feature vector\n",
    "    block_features = np.sort(block_features, order='f_vector')\n",
    "    # lexographically sorting the above feature matrix\n",
    "    return block_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1aa89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(block_features_matrix, Nf=3, Nd=16, D=3):\n",
    "    ''' This function will return whether image is an example of copy move forgery or not\n",
    "\n",
    "    INPUT PARAMETERS:\n",
    "\n",
    "    block_features_matrix = feature matrix A\n",
    "\n",
    "    D = Euclidean Similarity Threshold\n",
    "\n",
    "    Nf = Neighbourhood threshold\n",
    "\n",
    "    Nd = Eucleadian distance Threshold\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    True or False\n",
    "\n",
    "    '''\n",
    "    # Compare each block with all other blocks\n",
    "    for i in range(len(block_features_matrix)):\n",
    "        # this will have all boolean matches between vectors i and j for all j<Nf+i\n",
    "        for j in range(np.min(i+Nf, len(block_features_matrix))):\n",
    "            # j-i < Nf\n",
    "            print(i,j)\n",
    "            if (np.linalg.norm(block_features_matrix[i][\"feature_vector\"]-block_features_matrix[j][\"feature_vector\"]) < D):\n",
    "                d = np.array([block_features_matrix[i][\"x\"]-block_features_matrix[j][\"x\"],\n",
    "                              block_features_matrix[i][\"y\"]-block_features_matrix[j][\"y\"]])\n",
    "                if (np.linalg.norm(d) > Nd):\n",
    "                    return True\n",
    "                    # similarity found i.e possible copy move\n",
    "                else:\n",
    "                    pass\n",
    "                    # No similarity found i.e no copy move\n",
    "            else:\n",
    "                pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e247e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_copy_move(image_path, filters, block_size=8, D=3, Nf=3, Nd=16):\n",
    "    ''' This function will return whether image is an example of copy move forgery or not\n",
    "\n",
    "    INPUT PARAMETERS:\n",
    "\n",
    "    image_path = path for the image in the local directory that you are working so that\n",
    "                 opencv can load the image(type: string)\n",
    "\n",
    "    block_size = Image is divided into square blocks with each size of this variable for further processing\n",
    "                 (type=integer)\n",
    "\n",
    "    filters = Generated Gabor filters with different scales and rotation similar to SIFT\n",
    "                 (type=array of 2D array where 2D array is of type complex)\n",
    "\n",
    "    D = Euclidean Similarity Threshold\n",
    "\n",
    "    Nf = Neighbourhood threshold\n",
    "\n",
    "    Nd = Eucleadian distance Threshold\n",
    "\n",
    "    RETURNS:\n",
    "\n",
    "    True or False depending whether image is original or forged\n",
    "\n",
    "    '''\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Divide the image into blocks\n",
    "    blocks = generate_blocks(gray, block_size)\n",
    "\n",
    "    # Apply the Gabor filters to each block and getting feature_matrix\n",
    "    block_features_matrix = feature_matrix_generation(blocks, filters)\n",
    "\n",
    "    return detection(block_features_matrix, Nf, Nd, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b548781",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "images = []\n",
    "# path of the input folder of dataset which has all images\n",
    "\n",
    "PATH = \"../datasets/COFOMOD_v2/\"\n",
    "file_formats = [\".png\", \".jpg\", \".jpeg\"]  # image file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c986cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------GABOR FILTERS GENERATION ---------------------------------\n",
    "filter_size = 5\n",
    "filter_standard_dev = 10\n",
    "no_filter_theta = 12  # theta angluar resolution = 30degree\n",
    "filters = gabor_filters(filter_size, filter_standard_dev, no_filter_theta)\n",
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710b78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in os.listdir(PATH):\n",
    "    istrue = np.array([x.endswith(file_format)\n",
    "                       for file_format in file_formats])\n",
    "    if np.any(istrue):\n",
    "        # detecting png,jpg and jpeg files which are most common image files (in dataset it has only these filetypes)\n",
    "        paths.append(PATH+x)\n",
    "        images.append(x)\n",
    "\n",
    "# computing statistics like accuracy, precision, recall, f1_score to show robustness of our approach to solve the problem\n",
    "\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "true_negative = 0\n",
    "true_positive = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "677dacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(paths[1])\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Divide the image into blocks\n",
    "blocks = generate_blocks(gray, 8)\n",
    "\n",
    "# Apply the Gabor filters to each block and getting feature_matrix\n",
    "block_features_matrix = feature_matrix_generation(blocks, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de3570d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([([114.5, 114.25, 115.65625, 113.953125, 112.328125], 476, 474),\n",
       "       ([166.03125, 166.0, 165.484375, 166.265625, 167.0], 270, 464),\n",
       "       ([98.546875, 98.25, 98.4375, 98.21875, 98.625], 477, 377), ...,\n",
       "       ([128.078125, 128.90625, 127.796875, 129.859375, 128.78125], 473, 354),\n",
       "       ([23.125, 23.5, 23.21875, 23.484375, 23.40625], 267, 344),\n",
       "       ([115.8125, 113.09375, 115.734375, 110.4375, 115.65625], 474, 257)],\n",
       "      dtype=[('f_vector', 'O', (5,)), ('x', '<i4'), ('y', '<i4')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585ab710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([([114.5, 114.25, 115.65625, 113.953125, 112.328125], 476, 474),\n",
       "       ([166.03125, 166.0, 165.484375, 166.265625, 167.0], 270, 464),\n",
       "       ([98.546875, 98.25, 98.4375, 98.21875, 98.625], 477, 377), ...,\n",
       "       ([128.078125, 128.90625, 127.796875, 129.859375, 128.78125], 473, 354),\n",
       "       ([23.125, 23.5, 23.21875, 23.484375, 23.40625], 267, 344),\n",
       "       ([115.8125, 113.09375, 115.734375, 110.4375, 115.65625], 474, 257)],\n",
       "      dtype=[('f_vector', 'O', (5,)), ('x', '<i4'), ('y', '<i4')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82791180",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 255025 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     detection \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_copy_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     real_detected \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stre[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (real_detected \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "Cell \u001b[1;32mIn[6], line 38\u001b[0m, in \u001b[0;36mdetect_copy_move\u001b[1;34m(image_path, filters, block_size, D, Nf, Nd)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Apply the Gabor filters to each block and getting feature_matrix\u001b[39;00m\n\u001b[0;32m     36\u001b[0m block_features_matrix \u001b[38;5;241m=\u001b[39m feature_matrix_generation(blocks, filters)\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_features_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mdetection\u001b[1;34m(block_features_matrix, Nf, Nd, D)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compare each block with all other blocks\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(block_features_matrix)):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# this will have all boolean matches between vectors i and j for all j<Nf+i\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mNf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock_features_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m# j-i < Nf\u001b[39;00m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i,j)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(block_features_matrix[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m-\u001b[39mblock_features_matrix[j][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m<\u001b[39m D):\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\ivp-project\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2946\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[0;32m   2830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2831\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2832\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[0;32m   2834\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2944\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2947\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\ivp-project\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 255025 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "error = 0\n",
    "L = 10  # number of images from dataset to test upon\n",
    "index = 0\n",
    "t0 = time.time()\n",
    "t1 = t0\n",
    "\n",
    "for path in paths:\n",
    "    t2 = t1\n",
    "    if (x == L):\n",
    "        '''For L images in this folder'''\n",
    "        break\n",
    "    x += 1\n",
    "    # detection using pre computed Gabor filters\n",
    "    stre = images[index].split(\"_\")\n",
    "    if (len(stre[1]) != 1):\n",
    "        # we are skipping bit mask images as they are not images that we have to consider\n",
    "        x = x-1\n",
    "    else:\n",
    "        detection = detect_copy_move(path, filters)\n",
    "        real_detected = 1 if stre[1] == \"F\" else 0\n",
    "\n",
    "        if (real_detected == 0):\n",
    "            if (detection == 0):\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "                error += 1\n",
    "\n",
    "        else:\n",
    "            if (detection == 0):\n",
    "                false_negative += 1\n",
    "                error += 1\n",
    "            else:\n",
    "                true_positive += 1\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        print(f\"Time elapsed for a image {t1-t0}\")\n",
    "\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25583f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = error/L\n",
    "precision = true_positive/(true_positive+false_positive)\n",
    "recall = true_positive/(true_positive+false_negative)\n",
    "f1_score = 2/((1/precision)+(1/recall))\n",
    "\n",
    "print(f\"Accuracy is {accuracy}\")\n",
    "print(f\"Precision is {precision}\")\n",
    "print(f\"Recall is {recall}\")\n",
    "print(f\"F1 score is {f1_score}\")\n",
    "print(f\"Time took is {t1-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b05e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
